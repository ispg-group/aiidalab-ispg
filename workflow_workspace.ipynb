{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5299e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiidalab_atmospec_workchain import OrcaWignerSpectrumWorkChain\n",
    "from aiida.engine import WorkChain, calcfunction\n",
    "from aiida.engine import submit, run, append_, ToContext, if_\n",
    "from aiida.engine import run_get_node, run_get_pk\n",
    "\n",
    "StructureData = DataFactory(\"core.structure\")\n",
    "Dict = DataFactory(\"core.dict\")\n",
    "TrajectoryData = DataFactory(\"core.array.trajectory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38c3323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/aiidateam/aiida-core/blob/2c183fc4486e00f3348a1b66cdcd6d9fbfd563f0/.github/system_tests/workchains.py#L182\n",
    "\n",
    "# General WorkChain for combining all inputs from a dynamic namespace 'ns'\n",
    "# into a single List.\n",
    "# Used to combine outputs from several subworkflows into one output\n",
    "# It should be launched via run() instead of submit()\n",
    "class CombineInputsToList(WorkChain):\n",
    "    \n",
    "    @classmethod\n",
    "    def define(cls, spec):\n",
    "        super().define(spec)\n",
    "        spec.input_namespace(\"ns\", dynamic=True)\n",
    "        spec.output(\"output\", valid_type=List)\n",
    "        spec.outline(cls.combine)\n",
    "        \n",
    "    def combine(self):\n",
    "        #input_list = [self.inputs.ns[k] for k in self.inputs.ns]\n",
    "        input_list = [self.inputs.ns[k].get_dict() if isinstance(self.inputs.ns[k], Dict) else self.inputs.ns[k] for k in self.inputs.ns]\n",
    "        self.out('output', List(list=input_list).store())\n",
    "        \n",
    "        \n",
    "class CombineStructuresToTrajectoryData(WorkChain):\n",
    "    \n",
    "    @classmethod\n",
    "    def define(cls, spec):\n",
    "        super().define(spec)\n",
    "        # TODO: Maybe allow other types other than StructureData?\n",
    "        # Not sure what are the requirements for TrajectoryData\n",
    "        spec.input_namespace(\"structures\", dynamic=True, valid_type=StructureData)\n",
    "        spec.output(\"trajectory\", valid_type=TrajectoryData)\n",
    "        spec.outline(cls.combine)\n",
    "        \n",
    "    def combine(self):\n",
    "        structurelist = [self.inputs.structures[k] for k in self.inputs.structures]\n",
    "        self.out('trajectory', TrajectoryData(structurelist=structurelist).store())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd0be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtmospecWorkChain(WorkChain):\n",
    "    \"\"\"The top-level ATMOSPEC workchain\"\"\"\n",
    "    \n",
    "    @classmethod\n",
    "    def define(cls, spec):\n",
    "        super().define(spec)\n",
    "        spec.expose_inputs(OrcaWignerSpectrumWorkChain, exclude=[\"structure\"])\n",
    "        spec.input(\"structure\", valid_type=(StructureData, TrajectoryData))\n",
    "        \n",
    "        # TODO: Remove this\n",
    "        spec.expose_outputs(OrcaWignerSpectrumWorkChain, exclude=[\"relaxed_structure\"])\n",
    "\n",
    "        spec.output(\n",
    "            'spectrum_data',\n",
    "            valid_type=List,\n",
    "            required=True,\n",
    "            help=\"All data necessary to construct spectrum in SpectrumWidget\"\n",
    "        )\n",
    "           \n",
    "        spec.output(\n",
    "            \"relaxed_structures\", \n",
    "            valid_type=TrajectoryData,\n",
    "            required=False,\n",
    "            help=\"Minimized structures of all conformers\"\n",
    "        )\n",
    "\n",
    "        spec.outline(\n",
    "            cls.launch,\n",
    "            cls.collect,\n",
    "        )\n",
    "        \n",
    "        # Very generic error now\n",
    "        spec.exit_code(410, \"CONFORMER_ERROR\", \"Conformer spectrum generation failed\")\n",
    "        \n",
    "\n",
    "    def launch(self):\n",
    "        inputs = self.exposed_inputs(\n",
    "            OrcaWignerSpectrumWorkChain, agglomerate=False\n",
    "        )\n",
    "        # Single conformer\n",
    "        # TODO: Test this!\n",
    "        if isinstance(self.inputs.structure, StructureData):\n",
    "            self.report(\"Launching ATMOSPEC for 1 conformer\")\n",
    "            inputs.structure = self.inputs.structure\n",
    "            return ToContext(conf=self.submit(OrcaWignerSpectrumWorkChain, **inputs))\n",
    "        \n",
    "        self.report(f\"Launching ATMOSPEC for {len(self.inputs.structure.get_stepids())} conformers\")\n",
    "        for conf_id in self.inputs.structure.get_stepids():\n",
    "            inputs.structure = self.inputs.structure.get_step_structure(conf_id)\n",
    "            workflow = self.submit(OrcaWignerSpectrumWorkChain, **inputs)\n",
    "            #workflow.label = 'conformer-wigner-spectrum'\n",
    "            self.to_context(confs=append_(workflow))\n",
    "    \n",
    "    def collect(self):\n",
    "        # For single conformer\n",
    "        if isinstance(self.inputs.structure, StructureData):\n",
    "            if not self.ctx.conf.is_finished_ok:\n",
    "                return self.exit_codes.CONFORMER_ERROR\n",
    "            self.out_many(self.exposed_outputs(self.ctx.conf, OrcaWignerSpectrumWorkChain))\n",
    "            return\n",
    "       \n",
    "        # Check for errors\n",
    "        for wc in self.ctx.confs:\n",
    "            # TODO: Specialize erros. Can we expose errors from child workflows?\n",
    "            if not wc.is_finished_ok:\n",
    "                return self.exit_codes.CONFORMER_ERROR\n",
    "        \n",
    "        # Combine all spectra data\n",
    "        data = {str(i): wc.outputs.wigner_tddft for i, wc in enumerate(self.ctx.confs)}\n",
    "        all_results = run(CombineInputsToList, ns=data)\n",
    "        self.out('spectrum_data', all_results['output'])\n",
    "        \n",
    "        # Combine all optimized geometries into single TrajectoryData\n",
    "        # TODO: Include energies and boltzmann weights in TrajectoryData for optimized structures\n",
    "        if self.inputs.optimize:\n",
    "            relaxed_structures = {str(i): wc.outputs.relaxed_structure for i, wc in enumerate(self.ctx.confs)}\n",
    "            output = run(CombineStructuresToTrajectoryData, structures=relaxed_structures)\n",
    "            self.out(\"relaxed_structures\", output['trajectory'])\n",
    "        \n",
    "        self.out_many(self.exposed_outputs(self.ctx.confs[0], OrcaWignerSpectrumWorkChain))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac587d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = AtmospecWorkChain.get_builder()\n",
    "old_workchain = load_node(pk=1218)\n",
    "builder[\"structure\"] = old_workchain.inputs.structure\n",
    "for input in old_workchain.inputs:\n",
    "    if input != 'structure':\n",
    "        builder[input] = old_workchain.inputs[input]\n",
    "\n",
    "builder.optimize = Bool(True)\n",
    "builder.opt.clean_workdir = Bool(True)\n",
    "builder.exc.clean_workdir = Bool(True)\n",
    "builder.opt.orca.metadata.options.resources = {'tot_num_mpiprocs': 1}\n",
    "builder.exc.orca.metadata.options.resources = {'tot_num_mpiprocs': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ef2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7c885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4264acc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = load_node(pk=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433801a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in proc.outputs:\n",
    "    print(output)\n",
    "proc.outputs.spectrum_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c6e576",
   "metadata": {},
   "source": [
    "# Now test more than one conformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3136ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = AtmospecWorkChain.get_builder()\n",
    "old_workchain = load_node(pk=226)\n",
    "builder.structure = old_workchain.inputs.structure\n",
    "for input in old_workchain.inputs:\n",
    "    if input != 'structure':\n",
    "        builder[input] = old_workchain.inputs[input]\n",
    "        \n",
    "# Patch the inputs to reduct comp cost\n",
    "builder.nwigner = 2\n",
    "\n",
    "params = builder.opt.orca.parameters.get_dict()\n",
    "params['input_keywords'] = ['sto-3g', 'pbe', 'Opt', 'AnFreq']\n",
    "builder.opt.orca.parameters = Dict(dict=params)\n",
    "\n",
    "params = builder.exc.orca.parameters.get_dict()\n",
    "params['input_keywords'] = ['sto-3g', 'pbe']\n",
    "builder.exc.orca.parameters = Dict(dict=params)\n",
    "\n",
    "# Not sure why this is not already included\n",
    "builder.opt.orca.metadata.options.resources = {'tot_num_mpiprocs': 1}\n",
    "builder.exc.orca.metadata.options.resources = {'tot_num_mpiprocs': 1}\n",
    "builder.opt.clean_workdir = Bool(True)\n",
    "builder.exc.clean_workdir = Bool(True)\n",
    "builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7611a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = run(builder)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011489fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Int(1).store()\n",
    "y = Int(2).store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd7b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct = load_node(pk=1824)\n",
    "l = [x, y, struct]\n",
    "# This doesn't work\n",
    "inputs = {str(i): val for i, val in enumerate(l)}\n",
    "#run(CombineInputsToList, ns=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6acaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065f69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [struct, struct]\n",
    "inputs = {str(i): val for i, val in enumerate(l)}\n",
    "traj = run(CombineStructuresToTrajectoryData, structures=inputs)\n",
    "traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85008323",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(traj['trajectory'].get_stepids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [List(list=[1, 2]), List(list=[2, 3])]\n",
    "inputs = {str(i): val for i, val in enumerate(l)}\n",
    "run(CombineInputsToList, ns=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b62c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [Dict(dict={\"1\": 2}), Dict(dict={\"1\": 2})]\n",
    "inputs = {str(i): val for i, val in enumerate(l)}\n",
    "run(CombineInputsToList, ns=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8590abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "l[0].get_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce310f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatDictsToList(WorkChain):\n",
    "    \n",
    "    @classmethod\n",
    "    def define(cls, spec):\n",
    "        super().define(spec)\n",
    "        spec.input_namespace(\"ns\", dynamic=True)\n",
    "        spec.output(\"output\", valid_type=List)\n",
    "        spec.outline(cls.combine)\n",
    "        \n",
    "    def combine(self):\n",
    "        input_list = [self.inputs.ns[k].get_dict() for k in self.inputs.ns]\n",
    "        self.out('output', List(list=input_list).store())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255b2bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run(ConcatDictsToList, ns=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80114c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%aiida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710eb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiida.orm import load_node\n",
    "\n",
    "calc = load_node(565)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c468a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with calc.outputs.retrieved.base.repository.open('aiida.out') as f:\n",
    "    s = f.read()\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35531c81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94f6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
